# InfoQ 播客:菲尔·温德谈强化学习的历史、实际应用和伦理

> 原文：<https://winder.ai/infoq-podcast-phil-winder-on-the-history-practical-application-and-ethics-of-reinforcement-learning/>

[https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/993655273&color=1d8042](https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/993655273&color=1d8042)

[InfoQ](https://soundcloud.com/infoq-channel "InfoQ") · [Phil Winder on the History, Practical Application, and Ethics of Reinforcement Learning](https://soundcloud.com/infoq-channel/phil-winder-on-the-history-practical-application-and-ethics-of-reinforcement-learning "Phil Winder on the History, Practical Application, and Ethics of Reinforcement Learning")

InfoQ 的朋友兼编辑查尔斯·亨布尔(Charles Humble)非常友好地邀请我接受采访，以播客的形式谈论我的新书。从简介中:

> 在这一集的 InfoQ 播客中，菲尔·温德博士是温德公司的首席执行官。AI 与 InfoQ 播客主持人 Charles Humble 坐在一起。他们讨论:强化学习的历史；RL 在机器人和内容发现等领域的应用；缩放 RL 模型并在生产中运行它们；和伦理方面的考虑。

## 关键要点

*   强化学习来自于动物如何学习的实验。大多数聪明的动物通过强化学习，这种想法是对过去的行为提供积极或消极的反馈。更聪明的动物能够学习更复杂的动作，从而产生更高级的行为。
*   同样，与典型的短视机器学习方法不同，强化学习旨在根据一段时间内的决策序列来优化和解决问题。
*   强化学习的一个基本数学概念是理查德·贝尔曼在 20 世纪 50 年代提出的马尔可夫决策过程。它包括一个代理人，一个环境和一个奖励。奖励非常简单，容易理解，并且直接映射到你试图解决的问题上。
*   机器人技术是相对广泛采用 RL 的一个领域。用于内容发现的推荐系统也取得了成功。然而，大规模操作强化学习模型仍然具有挑战性，至少部分是因为强化学习模型本身是可变的。
*   RL 的伦理考虑类似于其他机器学习方法，但本质上更复杂，给出了模型的性质。可观察性/可审计性是关键。还存在诸如安全 RL 的方法，其中算法被训练成存在于受约束且受限的一组状态中。