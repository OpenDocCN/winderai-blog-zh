# 强化学习简介:你需要知道的一切

> 原文：<https://winder.ai/an-introduction-to-reinforcement-learning-all-you-need-to-know/>

当孩子想骑自行车时，他们通过做来学习。这种反复试验的过程也被称为强化学习，因为正面和负面的经历分别会促进或阻碍某些行为。儿童通过避免导致他们撞车的动作来学习骑车；感受风吹过头发的快感。

## 商业强化学习

这种通过试错的学习方式的应用被称为强化学习。一个用软件编码的自动代理被释放到世界上，试图学习理想的行为。合意的定义是由给予行为者的奖励或惩罚来控制的。工程师制定与问题定义一致的奖励。

## 强化学习和机器学习的区别

*机器学习*有三个识别特征。它使用整个数据集来学习模型。它(通常)是受监督的，这意味着模型知道它应该生产什么。它做出一个决定。

*强化学习*是截然相反的两极。它是体验的样本。它通过间接反馈来评估其绩效。随着时间的推移，它会做出多种决策，以实现回报最大化。

回想一下自行车的比喻，你就能明白为什么机器学习不是这个问题的解决方案。这个孩子没有完整的数据集，因为他们从来没有骑过自行车。他们没有直接监督，因为他们的父母不能微观管理每一个动作。他们不能通过做一个决定来骑自行车，这是一个被动的过程。

这意味着某些业务问题可能通过强化学习得到更好的解决。

## 如何发现商业中的强化学习问题

当一个目标只有在多次连续决策后才能实现时，强化学习效果最好。

我经常做的一个测试是想象一下，作为一个人，我会如何解决手头的问题。如果我能想象出一个单一的规则，比如接受信用分数超过 400 的客户，或者识别汽车上的车牌，那么这个任务可能最好留给机器学习。

但是，如果我需要制定一个策略来应对复杂的场景，或者如果我需要先尝试一些东西来找出反应是什么，这非常适合强化学习。

强化学习的一些常见策略示例是玩游戏、瞄准客户、控制工业流程和自动化实验。我在我的书的网站上维护了一个更全面的强化学习的工业应用列表。

## 强化学习中的常见挑战

给定一个清晰的问题定义，确保强化学习是一个很好的契合，是一个早期但重要的里程碑。

回想一下，代理需要实验，这意味着他们需要与环境交互，而环境是代理所在的上下文。在许多情况下，让一个代理去探索它的心脏是昂贵的，或者是完全危险的。)内容。

是的，您可以很容易地通过约束和边界来加强安全性，但是理想情况下，您希望允许代理不受阻碍地探索。

这个问题的常见解决方案是利用环境模拟。根据您的领域，这可能就像使用现成的解决方案一样简单，比如 3D 游戏引擎。但是对于许多项目来说，必须开发一个模拟来获得对代理的信任或提供预培训。

另一个常见的问题是，尽管有清晰的问题定义，但很难观察到环境中的正确数据或定义适当的奖励。这些的结果是代理不能学习，因为它不能“看见”，或者它学习错误的东西，因为你对成功的定义不足以解决问题。

## 如何开始强化学习项目

RL 项目和 ML 项目一样，本身就有风险。

所有人工智能项目都依赖于外部资产，如数据或访问领域专家。人工智能项目还依赖于解决正确的问题，而这个问题极难确定。因此，即使有世界上最好的专家，这个项目仍然有可能失败，或者至少不能满足高期望。降低这种风险的最简单方法之一是执行[强化学习概念验证](https://winder.ai/services/reinforcement-learning/reinforcement-learning-poc/)。

概念验证(POC)项目降低了将大量资金投入到没有成功希望的项目中的风险。POCs 旨在隔离项目中风险最大的部分，并证明解决方案是可行的，即使存在这些风险。

通常可以通过积极研究或开发项目中被认为有风险的部分来规避项目风险。如果这个小的子项目是成功的，那么这给了我们信心，整个项目也将是成功的。

## 商业强化学习的未来

作为一家专门从事[强化学习咨询](https://winder.ai/services/reinforcement-learning/reinforcement-learning-consulting/)的公司，我们遇到了许多试图利用新技术发展竞争优势的不同组织。RL 特别令人感兴趣的原因是它使以前不可能或难以置信地难以自动化的任务自动化。我想讲的一个例子是 YouTube 的一个[项目，由谷歌的一些最聪明的人拥有和运营，工程师们交换了 YouTube 的搜索算法，并用一个基于 RL 的算法取而代之。RL 解决方案从用户的点击反馈中学习改进其推荐，并非常快地匹配当前实现的性能。过了一会儿，它超过了它。](https://rl-book.com/applications/2019_reinforcement_learning_for_slatebased_recommender_systems_a_tractable_decomposition_and_practical_methodology/)

请记住，谷歌的推荐算法几乎可以说是世界上最好的。这是谷歌的核心技术。但是，一个 RL 实现，在很少的监督下，很快取代了一些非常聪明的数据科学家多年来开发的算法的性能。

诸如此类的例子让我得出这样的结论:用 RL 解决所有具有连续决策和抽象成功度量的问题只是时间问题。

我也相信 RL 作为一项技术将会在组织层级中向上移动。企业非常习惯于用软件实现流程自动化，并开始着手使用机器学习实现决策自动化。但现在，我们可以开始自动化战略，那些被高管们奉为神圣的战略，以完成提高整个企业效率的使命。

## 竞争差异化

不管怎样，资本主义要求企业不断优化，因此自动化会一直存在。现任者正在利用强化学习等新技术来实现以前不可能实现的壮举。

以 [FreshFlow](https://freshflow.ai) 为例。在创始人从我的[强化学习书籍](https://rl-book.com)中的一个例子中获得灵感后，我们一直在指导他们，在那里，我创造了一个能够自动学习你何时从商店需要什么的代理。

我之所以这么想象，是因为我讨厌美食购物，主要是因为我购物 90%都是一样的。但是因为我以不同的比率使用食物，我，不幸地，不能只是一遍又一遍地买同样的东西。我描述的例子是拿一个人的购物历史，慢慢开始自动发送产品。顾客可以选择拒绝或退货。这个反馈教会了 RL 代理应该发送什么以及何时发送。这个想法将极大地改变我们订购商品的方式。

我甚至认为，在 5 年内，这将成为常态，尤其是对于日常和定期购买。享受你的食物购物，当你还可以的时候！