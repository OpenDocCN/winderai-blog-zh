# 502:通过保持防止过度拟合

> 原文：<https://winder.ai/502-preventing-overfitting-with-holdout/>

## 坚持

我们一直在使用:

*   培训用数据

不代表生产。

我们想假装我们看到了新的数据:

*   隐瞒一些数据

？？？

当我们训练模型时，我们对一些数据进行训练。这叫做*训练数据*。

到目前为止，我们一直使用相同的训练数据来衡量我们的准确性。

如果我们创建一个查找表，我们的准确率将是 100%。但是这并不能推广到新的例子。

因此，我们希望*假装*我们有了新的例子，并用它来测试我们的模型。

换句话说，我们保留了一些数据。

* * *

### 抵制是如何工作的？

![Training test data](img/942ad3b36d0baf4a11dc6848827e8e1d.png)

将数据分成*训练集*和*测试集*。

测试集大小约为。10-40%.

最小尺寸取决于特征的数量和模型的复杂性。

？？？

当我们获得数据集时，我们会将数据分成*训练集*和*测试集*。

测试集的大小通常在整个数据集大小的 10-40%之间。

通常，数据越多，测试集就越小。

这样，如果算法看到新数据(假设数据的随机元素是稳定的),我们就可以得到准确的性能估计。)

* * *

### 问题

然而，像这样简单的维持技术存在一些问题。

简而言之，认真思考测试数据

*   是否独立于培训之外？
*   它代表现实数据吗？

* * *

#### 随机化数据

数据中常见的结构:

*   排序
    *   时间
    *   键(例如，从数据库获取数据时)
    *   值或标签(例如，首先是类 0 的所有元素，然后是类 1，&mldr;)
*   地理
    *   仅从某些地区取样。无法扩展到其他地区
*   语言

谢天谢地，修复很简单。**总是**在训练前随机化数据。

？？？

一个问题是数据集中的数据通常是有结构的。例如，它可以以这样的方式排序或收集，即当我们选择一个观察值进行训练或测试时，它并不代表总体。

* * *

#### 超参数调谐

想象一下试图调整一个超参数&mldr;

你能看出这个问题吗？

我们正在使用测试集来训练超参数！

？？？

我们在上面看到，一个常见的任务是改变模型的一些参数来提高性能。

如果我们反复改变*超参数*来最大化测试集分数，我们并没有真正找到最好的模型。我们正在调整超参数以最好地代表测试集。

你能看出这里的问题吗？

我们正在使用测试集来训练超参数！随着时间的推移，我们会使模型过度适应测试集！

解决这个问题最简单的方法是引入另一个称为验证集的维持集。

* * *

### 验证集

验证数据集是计算最终精度时使用的第二个维持集。

![Validation set](img/b947217f96a4c65182b0617874e92834.png)

* * *

### 验证集问题

*   显著减少了可用于培训的数据量

？？？

从图中可以明显看出使用验证集的主要问题。它显著减少了可用于训练模型的数据量。

这将最终影响模型性能。因为更多的数据通常意味着更好的性能。

最简单的解决方法是使用所有的训练和测试数据重新训练最佳模型&mldr;

* * *

![Validation set](img/00ea04a256464b94db9158b2d8b2641c.png)

但我们仍然没有使用测试集中的数据来训练模型。测试数据集中的数据对于定型模型可能很重要。

所以&mldr;

* * *

## 交叉验证

*   对于每个新的训练运行，选择一个新的数据子集进行训练/测试。

？？？

*交叉验证*是一个过程，我们重复执行拟合程序，但每次都选择一个新的测试集进行训练。

这样，我们使用所有的测试集来训练模型，但我们仍然能够在独立数据集上进行最终验证之前挑选最佳模型。

* * *

### 它是如何工作的？

![Cross validation](img/814532716a3369d29a1c0f07205a1888.png)

迭代次数的选择称为*折叠次数*。在上面的例子中有`2`褶皱。

* * *

### 交叉验证的好处

*   每次训练跑完所有折叠

然后，我们有关于我们的模型在不同褶皱上的一致性的统计数据。

也就是说，我们可以计算得分的平均值和标准差。

* * *

### 交叉验证的问题

主要问题是每次折叠都需要额外的时间来重复训练过程。

对于深度学习这样的复杂模型来说，这越来越成问题。

*我们来谈谈可视化过度拟合*

* * *