# 单元测试数据:它是什么，你是如何做的？

> 原文：<https://winder.ai/unit-testing-data-what-is-it-and-how-do-you-do-it/>

数据测试在数据项目中扮演着不可或缺的角色。当企业无法测试他们的数据时，就很难理解错误以及错误发生在哪里，这使得解决问题更加困难。如果数据测试执行正确，它将改善业务决策，最大限度地减少损失，并增加收入。

本文介绍了关于单元测试原始数据的常见问题。如果您的问题没有列出，[请联系我们](https://winder.ai/about/contact/)，我们将很乐意为您提供帮助。

## 什么是单元测试，它如何应用于数据？

在软件开发中，单元测试是一种验证和确认技术，在这种技术中，开发人员测试您的软件所使用的各个方法和功能、组件或模块是否适合使用。单元测试是非常低级的，靠近应用程序的源代码。自动化成本通常很低，并且可以通过持续集成服务器快速运行。

数据单元测试检查的是数据的质量，而不是软件。这可以通过各种方式实现，包括:

*   检查数据是否落在该数据元素的最小-最大范围内(基于所有先前注册的数据)，
*   定义若干验证规则，并显示违反这些验证规则的数据单元。
*   数据集分析，即检查数据中的缺口、缺失值、现有趋势等。

确保数据质量对于构建有效的数据产品和提高数据的准确性和可靠性至关重要。

## 不测试会发生什么:行业示例

研究表明，糟糕的数据平均会耗费企业 30%的收入。根据 Gartner 的调查，数据质量差每年会给组织造成 970 万到 1420 万美元的损失。不对数据执行单元测试会导致一些低级问题，例如:

*   缺少值可能会导致需要非空值的生产系统出现故障。
*   数据分布的变化会导致机器学习模型的意外输出。
*   不正确数据的聚合会导致错误的业务决策。

较差的数据质量不仅会导致财务机会方面的高成本，还会损害声誉。对客户满意度的影响威胁到公司的声誉，因为客户可以使用社交媒体来分享他们的负面体验。

例如，一个夏威夷航空公司的预订应用程序意外地以美元金额收取航空里程购买费用，这意味着用户支付的不是 20 万英里，而是 20 万美元。使用飞行数据测试可以发现并防止这种情况。

![](img/23d92328006162f47418820c60e8862c.png)

## 单元测试数据有什么优势？

举几个例子，单元测试数据具有各种优势:

*   增加数据的可信度:数据单元测试建立了对数据的信任和理解。它允许在整个组织中传播信心，让他们对从数据中获得的洞察力充满信心。
*   可伸缩性:通过实现数据单元测试实践，组织可以扩展他们的业务操作，同时仍然确保数据保持准确和可靠。
*   节省成本和时间:单元测试数据允许公司及早发现错误和不准确的数据。因此，商业决策仅基于高质量的数据，这节省了成本和时间。
*   更明智的决策:增强的数据质量使组织能够做出更好的决策。数据质量越高，风险就越小，对业务决策就越有信心。
*   提高生产力:不再浪费时间回溯错误和复查结果，组织可以将资源投入到实现与其业务目标一致的进一步结果上。

## 有哪些数据单元测试策略可用？

*   **批量数据测试**:批量数据测试策略包括测试在给定时间段内收集的大量数据。批量测试是大量数据集和需要更深入分析的项目的理想选择。对于涉及速度或实时结果的项目，不推荐使用该策略。
*   **实时数据测试**:实时数据测试是在数据可用时立即进行测试。换句话说，您可以在数据进入系统后立即获得见解或得出数据质量的结论。实时测试使企业能够及时做出反应并修复数据质量。

## 如何对数据进行单元测试

那么，你可以对你的数据进行什么样的单元测试呢？以下是我们在项目中使用的一些:

*   健全检查:健全检查是数据争论过程中至关重要的一步。最终的分析只有和数据一样准确。没有很好地理解你的数据，检查不一致或重复的数据会导致你的分析有偏差。以下是在健全性检查中执行的一些实践:
    *   随机抽取数据样本。
    *   检查数据类型不匹配、值输入方式的变化以及缺少的值。
    *   寻找重复记录和异常值。
*   **分布检验**:分布检验评估数据分布，并检验数据的正态性。有时数据表面上看起来不错，但是如果您检查数据的分布，您会注意到差距或没有逻辑意义的值的分布。异常数据分布可能表明存在更大的数据质量问题，需要进一步调查。
*   **相关性检验**:在调查两个连续的数量变量之间的关系时，皮尔逊相关系数是一个很好的衡量两个变量之间关联强度的指标。要研究两个变量之间的关系，请绘制变量的散点图来检查线性。如果关系不是线性的，则不应计算系数。点的散布越接近直线，变量之间的关联强度越高。您也可以使用相关性测试来自动完成这项工作。
*   **周期/趋势**:对周期和趋势进行建模是数据分析的基础部分。如果您有多年的数据，并且这些数据以定期重复的周期(每年、每月、每天或任何其他周期)变化，那么了解如何对现有周期建模对于理解影响测量数据并最终做出预测的过程非常重要。
*   **异常**:异常是给定数据集中不寻常的点或模式。异常检测提供了一种减少需要进一步分析的原始数据量的方法。以下技术通常用于异常检测:
    *   标准偏差
    *   箱线图
    *   隔离森林

## 数据单元测试工具

数据单元测试有很多工具；以下是一些最常用的检查数据质量的工具:

*   开放源码
    *   **[Apache Griffin](https://griffin.apache.org/)**:Apache Griffin 是一个数据质量断言框架。它的工作原理是定义你的质量定义，测量批量或流数据的定义，然后生成结果报告。问题是这个项目很老了，但不是很受欢迎。它没有获得它所希望的那么多的关注。此外，它可以进行的测量非常有限。例如，没有统计测试来测试原始数据。
    *   **[JSON 模式](https://json-schema.org/)** :使用模式进行单元测试可能听起来很奇怪，但是许多模式库允许您在规范中强制执行数据需求。例如，JSON Schema 允许您设置最小值和最大值，因此您可以对 API 层中的数据进行单元测试。这有助于防止坏数据影响模型或管线。
    *   **[亚马逊 deequ](https://github.com/awslabs/deequ)** : Deequ 是一个数据单元测试库，在数据进入机器学习算法之前发现错误。它定期计算数据质量指标，检查用户设置的约束，并在成功的情况下发布数据。在出现错误的情况下，可以停止数据集发布，用户会收到通知以便采取措施。
    *   **[great _ expectations](https://github.com/great-expectations/great_expectations)**:一个很棒的数据断言库，可以与任何管道工具一起使用。将这些插入到您的管道中，使它们更加坚固。
    *   :是一个数据转换工具(ETL 中的 T)，它有一种自然的方式将测试定义为转换管道的一部分。
*   所有人
    *   **[Talend](https://www.talend.com/)** : Talend 提供数据质量、数据管理、大数据等多种软件解决方案，并且针对所有这些解决方案都有单独的产品。Talend 的数据质量解决方案对任何格式或大小的数据进行剖析、清理和屏蔽，以获得高质量的数据。这个工具的问题是许多用户抱怨学习过程的困难。
    *   **[Xplenty](https://www.xplenty.com/)** :是一个基于云的 ETL 平台，通过直观的图形界面实现数据转换，简化数据处理。一些用户报告说，尽管 Xplenty 的图形用户界面易于导航，但它的错误消息并不总是足够描述性的。
    *   **[RightData](https://www.getrightdata.com/index.php)** :是一个为自动化数据质量保证而设计的数据质量测试工具。它确定与数据一致性、质量、完整性和差距相关的问题。值得注意的是，列表中的最后三个工具是专有的，根据每个公司的产品，它们的使用可能需要额外的费用。
    *   **[Trifacta](https://www.trifacta.com/)** :是数据流水线的专有平台，测试能力有限。

## 监控/警报与单元测试生产数据的关系

通过测试数据并实时控制其质量，跨多个来源(如云、web 和移动应用程序)监控数据变得更加容易。持续监控和警报有助于发现可能影响业务的新机会和异常情况。它使他们能够持续监控自己的数据，在线了解需要关注的内容。

实施监控策略可以让组织通过识别确实异常的问题和其他重复性的、需要一劳永逸关注的问题，变得更加积极主动和富有成效。

跟踪数据质量和实施监控系统允许您实时解析、标准化和匹配数据。

## 摘要

数据质量差会导致机器学习算法的错误输出越来越多。因此，由于数据问题，失去了货币化数据和实现业务目标的机会。

对于有益的数据，它需要高质量，这只能通过定期的数据测试来实现。作为测试策略的第一步，执行单元测试会让组织从他们的数据中获益。新技术的成功在很大程度上取决于数据质量。数据质量越好，算法产生结果的速度就越快，结果也就越好。

## 信用

感谢 Larysa Visengeriyeva 对 Trifacta 和远大前程的建议。感谢 Oliver Laslett 的 dbt 推荐。