# 用强化学习解决三个常见的制造问题

> 原文:[https://winder . ai/solving-three-common-manufacturing-problems-with-reinforcement-learning/](https://winder.ai/solving-three-common-manufacturing-problems-with-reinforcement-learning/)

像许多行业一样，制造业正在经历数据增长和访问的爆炸式增长。数据是复杂的和多方面的，例如，数据可能来自生产线、环境、使用，甚至来自用户。从这个角度来看，这种爆炸通常被称为“大数据”，其影响被称为智能制造(美国)或工业 4.0(德国)。

这些数据必须付诸行动才有用。由人类手动完成这项工作通常既耗时又低效。机器学习(ML)和[强化学习(RL)](https://rl-book.com) 算法可以根据数据自动做出决策。这些方法可用于交付[先进制造技术、可持续流程和创新产品](https://ideas.repec.org/p/msm/wpaper/2012-05.html)。这些改进也隐含地与供应链和库存控制技术的进步联系在一起，我在另一篇文章中[对此进行了讨论。](https://winder.ai/inventory-control-and-supply-chain-optimization-with-reinforcement-learning/)

特别是 RL，一种评估顺序过程以提供最佳策略的技术，令人兴奋，因为它开辟了不适合单独 ML 的新应用。

在这篇文章中，我展示了最近令人兴奋的研究，展示了 RL 对三个制造问题的适用性，我和我的团队能够提供点解决方案:调度、开发和生产，以及装配。

 [我关于强化学习的新书](https://rl-book.com/?utm_source=winderresearch&utm_medium=web&utm_campaign=rl) 

你想在现实生活、商业应用中使用 RL 吗？你想知道真相吗？最佳实践？

我们为 O'Reilly 写了一本关于强化学习的书。它侧重于工业 RL，有许多真实生活的例子和深入的分析。

了解更多关于 https://rl-book.com 的信息。

## 制造作业计划和调度

生产调度问题可以分解为配置约束和目标约束。配置包括生产中涉及的机器或生产线的数量，以及这些机器或生产线是运行单个任务还是多个任务。调度目标取决于业务需求，但许多人选择优化到期日。

这些问题传统上很难解决，因为约束很难解决，而动态性使得静态启发式算法效率低下。RL 可以解决这两个问题，我在下面列举了一些激动人心的例子:

*   [RL 优化高混合、小批量制造](https://arxiv.org/abs/1910.02035)
*   [作业调度优化](https://arxiv.org/abs/2009.03836)
*   [制造系统的生产维护政策](https://ieeexplore.ieee.org/abstract/document/8114172)
*   [大型项目中的项目调度](https://www.tandfonline.com/doi/abs/10.1080/00207543.2018.1535205)

## 产品开发和生产

机器通常用于制造人类不太适合的任务，例如要求高精度、可重复性或处于危险环境中的任务。这些任务中的许多代表难以编程的复杂控制任务，或者具有难以解释的变量。例如，生产光缆用玻璃纤维需要精细和仔细的控制，这取决于玻璃的个别质量、熔炉、控制机制和纤维要求。RL 非常适合学习用于纤维生成的最优控制策略。

类似的挑战存在于纺织制造、发酵和纳米制造等各种行业。在许多高度自动化的行业中，甚至有可能提供端到端的产品开发，例如药物研发。以下是最近的研究列表，为使用 RL/ML 作为生产的一个组成部分提供了灵感:

*   [反复优化织物添加剂以防止褪色](https://arxiv.org/abs/2005.09867)
*   [纳米制造！](https://arxiv.org/abs/2002.11952)
*   [纤维的动态生产控制和优化](https://arxiv.org/abs/1911.10286)
*   [生物制造发酵控制](https://arxiv.org/abs/2101.03735)
*   [药物设计](https://arxiv.org/abs/1711.10907)
*   [合金设计](https://arxiv.org/abs/2012.07583)
*   [智能制造系统的自我修复](https://www.sciencedirect.com/science/article/abs/pii/S0007850620300299)

## 装配和一般机器人任务

我想强调的最后一组用例比前一组要普遍得多。使用机器人进行生产已经流行多年了。但是最近有一种趋势，那就是使用通用的、多用途的机器人，这些机器人可以被重新编程来完成各种任务。不幸的是，重新编程是一项非常劳动密集型和高技能的挑战，即使这样，由于传感和控制方面的限制，生成的策略通常也不是最佳的。此外，有许多任务乍一看似乎很简单，但实际上由于起始状态的变化而非常困难。

困难挑战的一个很好的例子是插入任务。在这里，一个相对简单的机器人的任务是将一个物体插入插槽，如螺栓或电子元件。但是底层对象可能会稍微放错位置或制造不正确，机器人需要适应将对象放置在正确的孔中。为这样的场景开发静态策略是非常困难的。然而，RL 是非常适合的，因为这些策略几乎适用于所有的可能性；放置是“智能”的。

以下是可以通过 RL 解决的类似挑战列表:

*   [增材制造刀轨模式优化](https://arxiv.org/abs/2009.14365)
*   [插入任务优化](https://arxiv.org/abs/1906.05841)
*   [产品组装](https://arxiv.org/abs/1708.04033)
*   [高精度装配](https://arxiv.org/abs/1708.04033)
*   [拾取和放置机器人](https://arxiv.org/abs/2001.03792)

## 结论

一般来说，RL 最适合动态的任务，并且很难定义静态控制策略。制造业有很多这样的问题，我在这里提出了三个一般领域。但毫无疑问，还有更多是你的业务和情况所特有的。

我看到了自动化水平不断提高的趋势，这带来了不太适合当前工具的复杂程度。RL 也为这个问题提供了一个诱人的解决方案，因为它可以很好地处理极其复杂的领域。

我和我的同事在温德。AI 在这里帮助你找到最佳的数据驱动的解决方案来解决你的问题，RL 可能是(也可能不是)不可或缺的一部分。[如果您想就本文中的任何主题进行更多的讨论](https://winder.ai/about/contact/),或者您遇到的任何与数据相关的问题，请联系我们。[你可以通过阅读我们的书找到更多关于 RL 的信息。](https://rl-book.com)