# 大型数据集的距离测量

> 原文:[https://winder.ai/distance-measures-with-large-datasets/](https://winder.ai/distance-measures-with-large-datasets/)

# 大型数据集相似性匹配的距离度量

今天，一位客户向我提出了一个有趣的问题，他使用距离度量进行相似性匹配。

> 我面临的问题是，给定一个向量 v 和一列向量 X，我如何以最有效的方式计算 v 和 X 中每个向量之间的欧几里德距离，以获得最佳匹配向量？

距离度量是一个观察值与一组其他观察值相比相似程度的度量。这是最近邻模型中最常用的方法，但也用作一系列聚类和分类算法的相似性度量。

困难在于，如果你想要生成正确的最接近匹配，那么你需要计算到每个对象的距离。这在`O(N)`时间内是可计算的，这意味着如果你的数据集中有大量的观察值(在我客户的例子中是`10^7`),那么这些操作显然会花费很长时间。

以下是一些可以尝试的想法，从最容易到最难:

1.  **减少数据量**:这永远是最容易做到的事情，所以如果可以，就去做吧。您可能需要在这里执行一些集群，然后您可以只保留集群的“样本”。另一种选择是，你可以选择一个随机的数据子集。每次您都会得到不同的结果，但是您可以保证性能。

2.  **降维**:更少的特征意味着更少的计算。

3.  **水平缩放**:这个问题很容易缩放。挑选 X 的子集，找到最近的，合并成一个新的集合。这是一个标准的“map-reduce”类型的问题，你如何实现取决于你的基础设施。你有集群吗？管弦乐队吗？火花？Hadoop？等等。如果你搜索“可扩展欧几里得距离”，也有相当多的文献。

4.  **矩阵优化**:我很确定将一堆 X 加载到一个矩阵中并执行矩阵减法是可能的。然后，您可以利用 numpy 对*BLAS 的使用，一下子计算出大量的距离。请确保您测试了性能。您可能会发现 python 的优化器已经在 CPU 内部为您完成了这项工作。

5.  **向您的算法**添加层:即首先执行聚类以找到不同的聚类。例如男性/女性。然后，只将您的距离度量应用于该子集。只要有意义，就继续使用更多的集群。

6.  **分离实时和精确算法**:提供实时、粗略估计和慢速最佳匹配，例如“是的，可能有一个很好的匹配，但我们需要继续搜索以找到最佳匹配”。你可以用许多方法做到这一点，使用上面的任何一个想法。例如，提供一个随机的子集，随着时间的推移，不断添加越来越多的数据，直到你用完为止。

7.  **使用基于树的方法**:即找出哪些特征最重要。用第一个(一个？两个？三个？)组件来分割您的数据，继续这样做，直到您只剩下一个组件，或者使用标准的 NN 算法来完成。

最后，GPU。GPU 用于解决容易并行化的问题。本质上，您需要实现上面的 2 和 3 来充分提取 GPU 的并行化性能。但是请注意，这意味着您限制了它运行的硬件，硬件更加昂贵，并且会增加代码的复杂性。我建议首先让它在 CPU 上足够好地工作，只有在必要时才迁移到 GPU。