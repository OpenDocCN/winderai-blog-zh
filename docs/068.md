# 203:示例和决策树

> 原文:[https://winder.ai/203-examples-and-decision-trees/](https://winder.ai/203-examples-and-decision-trees/)

### 示例:通过信息增益进行细分

有一个非常著名的数据集叫做“蘑菇数据集”。

它描述了蘑菇是否可以食用，这取决于一系列特征。

这个数据集的好处是所有的特征都是分类的。

因此，我们可以仔细检查并分割特征中每个值的数据。

以下是一些示例数据:

| 有毒的 | 帽状 | 帽状表面 | 瓶盖颜色 | 淤青？ |
| --- | --- | --- | --- | --- |
| p | x | s | n | t |
| e | x | s | y | t |
| e | b | s | w | t |
| p | x | y | w | t |
| e | x | s | g | f |

等等。

* * *

对于每个特征，我们可以直观地绘制信息增益，这很有帮助。在 x 轴上，我们有给定特征值的样品的比例，相对于标签(有毒，无毒)的计算熵。

这是“帽形”特征的信息增益:

![mushroom_cap-shape](../Images/954699c831effdde1b6f04f1f52f1cf0.png)

* * *

这是“气味”特征的信息增益:

![mushroom_odour](../Images/cb94f038478ccbea426c902376533e8d.png)

我们可以直观地看到，第二个特征具有小得多的`entropy*probability`面积，因此信息增益大得多。

我们当然会考虑使用这一功能，而不是其他功能。

* * *

## 通过树进行分割

信息的分段和定量测量是数据科学的基础。

如果我们选择了最具信息性的特征，那么我们已经对数据进行了分段。然后，使用该分割规则(例如< or > 50)来预测新观察的类别是非常简单的。

但是，如果一个单独的拆分没有完全将类分开呢？

一个简单的解决方案是堆叠分段规则。即再次执行分裂，直到类是纯的。

这就是所谓的树。

* * *

一棵树有几个组成部分:

*   **根节点**:起点
*   **内部节点**:决策点
*   **终端节点/叶子**:纯节点。

树经常被用作预测模型。

* * *

我们可以继续执行分裂和信息增益计算，直到所有的终端节点都是纯的。

然后，如果我们看到一个新的观察，我们可以为这个新的观察重新运行相同的规则，并*预测*它的类别。

当树被用来做决策时，它们被称为*决策树*。我们的第一个分类算法！

拍拍自己的背。轻拍你的邻居。你刚刚导出了一个非常重要的算法！

它们受欢迎是因为:

*   它们很容易理解
*   实施简单高效
*   稍加调整即可正常工作
*   处理连续数据和分类数据(下一步将详细介绍)

* * *

给定一些数据，我们可以为我们的问题建立一个最佳的树结构。这叫做*树归纳*。

该树的目标是提供有监督的分段；给定一些带标签的数据，根据它们的特征找到规则，分成具有相似值的子组。

在讨论信息增益时，我们手动执行了这项任务。我们可以反复选择最大化信息增益的最佳分割。

* * *

### 决策线和超平面

一旦从数据中推导出规则，该规则就形成了一个*决策边界*。

如果只有一个特征，那么边界就是一个点。如果有两个特征，则边界是一条线。如果有三个，它就成了一个曲面。等等。

广义的边界被称为*超平面*，简单地说就是一个分离面。

* * *

### 作为规则的树

基于树的分类算法的优点之一是它们是纯逻辑的。

很容易将简单的树转换成一组规则。

例如，我们的啤酒示例可以总结为:

```
if COLOUR < 50 then Class=A else Class=B 
```

这些规则可以很容易地编码到软件或程序中。

* * *

### 例子:客户流失

这是一个有趣的数据集，描述了一个移动电话服务的用户是否会转向另一个提供商。这就是所谓的“客户流失”。

该数据集的目标是通过其他一些特征来预测客户是否会离开。

这些功能包括:

```
Index(['COLLEGE', 'INCOME', 'OVERAGE', 'LEFTOVER', 'HOUSE', 'HANDSET_PRICE',
       'OVER_15MINS_CALLS_PER_MONTH', 'AVERAGE_CALL_DURATION',
       'REPORTED_SATISFACTION', 'REPORTED_USAGE_LEVEL',
       'CONSIDERING_CHANGE_OF_PLAN'],
      dtype='object') 
```

我现在还不想谈细节，因为我们还没有完全准备好。但是我将这些数据通过一个算法来创建一个决策树，计算出每一个生成规则的信息增益。

产生的规则看起来像&mldr;

* * *

![graphviz](../Images/c5ca80c4ab1e9e3223d8739b25e9c01b.png)

* * *

![churn_feature_information_gains](../Images/f4d957101569603a40f3761dadd6c44d.png)

* * *